---
title: "Course Project - Modeling Data in the Tidyverse"
author: "dillonchewwx"
date: "15/03/2021"
output:
    prettydoc::html_pretty:
        theme: hpstr
        highlight: github
---
# Overview

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. 

In this project, the [Weight Lifting Exercise Data Set](http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har) would be used to predict the manner in which an individual did the exercise. The data comes from accelerometers on the belt, forearm, arm, and dumbbell of 6 participants where they were asked to perform barbell lifts correctly and incorrectly in 5 different ways. 

The datasets can be downloaded from here:

* [Training Data](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv)
* [Testing Data](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv)

# Load Libraries and Import Data
```{r Setup, message=FALSE, results='hide', warning=FALSE}
library(caret) # For ML
library(tidyverse) # For manipulating data

training<-read_csv("Data/pml-training.csv")
testing<-read_csv("Data/pml-testing.csv")
```
# Data Inspection
```{r Inspect Data}
glimpse(training)
```
A quick look of the data reveals the following:

* The outcome variable which we are interested in is called `classe`.
* There are 159 variables for us to use as predictors. However, some of the variables contain `NA` and `#DIV/0!` and thus we would have to do some cleanup. In addition, we will use the `nearZeroVar()` function to remove the variables with near zero variance. 
* Some variables also have descriptive fields e.g. `X1`, `user_name`, `raw_timestamp_part_1`, `raw_timestamp_part_2`, `cvtd_timestamp`, `new_window`, `num_window` and thus we would have to remove them.
```{r Clean Up}
training_cleaned<-training %>%
    select(!X1:num_window) %>% 
      mutate(across(everything(), ~replace_na(.x, 0)), # Remove descriptive variables
             across(everything(), ~gsub("#DIV/0!", 0, .x))) # Replace NAs and #DIV/0! with 0.

training_cleaned<-training_cleaned[, -nearZeroVar(training_cleaned)] #Remove variables which have near zero variance. 
training_cleaned<-training_cleaned %>%
  mutate(across(1:52, as.numeric)) %>%
  mutate(classe=factor(classe))
  
glimpse(training_cleaned)
```
We are now left with 52 variables to use as predictors. We will now create training and validation test sets. 
```{r Create Training and Validation Test Sets, warning=FALSE}
set.seed(4896)
inTrain<-createDataPartition(training_cleaned$classe, p=0.75, list=FALSE)
train_set<-training_cleaned[inTrain,]
validate_set<-training_cleaned[-inTrain,]
```
# Model Fitting
Here, we will use the Random Forest model for classification with 5-fold cross validation. To speed things up, we will carry out parallel processing with the `doParallel` package. 
```{r Model Fitting, message=FALSE, results='hide', warning=FALSE}
library(doParallel)
cl<-makePSOCKcluster(0.75*detectCores())
registerDoParallel(cl)
rfCrossVal<-trainControl(method="cv", 5)
rfFit<-train(classe~., data=train_set, method="rf", trControl=rfCrossVal)
stopCluster(cl)
rfFit
```
## Test the Accuracy on the Validation Set
```{r Training set Accuracy}
rfPred<-predict(rfFit, validate_set)
rfMat<-confusionMatrix(rfPred, validate_set$classe)
rfMat$overall
```
The accuracy on the validation data set is 99.55% - our model performs pretty good! 

# Test Set Prediction
We shall first clean up the test data set before carrying out the prediction.
```{r Prediction}
testing_cleaned<-testing %>%
    select(!X1:num_window) %>% 
      mutate(across(everything(), ~replace_na(.x, 0)), # Remove descriptive variables
             across(everything(), ~gsub("#DIV/0!", 0, .x))) # Replace NAs and #DIV/0! with 0.

testing_cleaned<-testing_cleaned[, -nearZeroVar(testing_cleaned)] #Remove variables which have near zero variance. 
testing_cleaned<-testing_cleaned %>%
  select(!problem_id) %>%
  mutate(across(1:52, as.numeric))

testPred<-predict(rfFit, testing_cleaned)
testPred
```

